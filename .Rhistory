best_rf_model <- rf_model$finalModel
# test_x <- x[, !colnames(x) %in% primary_outcome]
# # Get predicted probabilities for both case and control classes
prob_predictions <- predict(best_rf_model, train_data, type = "prob")
?predict
# test_x <- x[, !colnames(x) %in% primary_outcome]
# # Get predicted probabilities for both case and control classes
prob_predictions <- predict(rf_model, train_data, type = "prob")
x <- model.matrix(as.factor(primary_outcome) ~ . - 1, data = train_data)  # Recreate the same feature matrix
x <- model.matrix(as.factor(primary_outcome) ~ ., data = train_data)  # Recreate the same feature matrix
x <- model.matrix(as.factor(subjid) ~ ., data = train_data)  # Recreate the same feature matrix
?model.matrix
ff <- log(Volume) ~ log(Height) + log(Girth)
ff
utils::str(m <- model.frame(ff, trees))
m
mat <- model.matrix(ff, m)
mat
ff <- log(Volume) ~ log(Height) + log(Girth)
mat <- model.matrix(ff, trees)
mat
# Ensure x has the same structure as during training
x <- model.matrix(as.factor(subjid) ~ . - 1, data = train_data)  # Recreate the same feature matrix
# Get predicted probabilities using the final randomForest model
prob_predictions <- predict(best_rf_model, newdata = x, type = "prob")
x
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
secondary_outcome <- "obesity"
y <- train_data[[primary_outcome]]
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-c(primary_outcome, subjid))# Remove both primary_outcome and subjid columns
#
# x[[primary_outcome]] <- y
#
# # Ensure x has the same structure as during training
# # Exclude 'subjid' from the model matrix creation
# # x <- x[, !colnames(x) %in% "subjid"]
# # x <- model.matrix(as.factor(primary_outcome) ~ . - 1, data = train_data[, !colnames(x) %in% "subjid"])  # Recreate the same feature matrix
# #
# # Define a hyperparameter grid with only 'mtry'
tune_grid <- expand.grid(
mtry = c(10, 50, 100, 200)  # Number of features considered at each split
)
#
# Set up trainControl for cross-validation
control <- trainControl(
method = "cv",               # Use cross-validation
number = 3,                  # Number of folds in cross-validation
classProbs = TRUE,           # For classification problems, calculate class probabilities
summaryFunction = twoClassSummary  # Optimize based on AUC (ROC curve)
)
new_train_data <- cbind(y = train_data[[primary_outcome]], x)
# # Train the Random Forest model with caret
rf_model <- train(
as.formula(paste(primary_outcome, "~ .")),  # Use the primary outcome dynamically
data = new_train_data,                      # Training dataset containing both predictors and outcome
method = "rf",                              # Random Forest model
tuneGrid = tune_grid,                       # Hyperparameter grid with mtry only
trControl = control,                        # Cross-validation settings
metric = "ROC"                              # Optimize for AUC (ROC curve)
)
# # Train the Random Forest model with caret
rf_model <- train(
as.formula(paste(y, "~ .")),  # Use the primary outcome dynamically
data = new_train_data,                      # Training dataset containing both predictors and outcome
method = "rf",                              # Random Forest model
tuneGrid = tune_grid,                       # Hyperparameter grid with mtry only
trControl = control,                        # Cross-validation settings
metric = "ROC"                              # Optimize for AUC (ROC curve)
)
new_train_data
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
# Define the response (primary outcome)
y <- train_data[[primary_outcome]]
primary_outcome <- "nafld"
# Define the response (primary outcome)
y <- train_data[[primary_outcome]]
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(primary_outcome))  # Remove the primary outcome column from predictors
head(x)
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(c(primary_outcome,"subjid")))  # Remove the primary outcome column from predictors
x
# Define a reasonable hyperparameter grid for a dataset with many features
tune_grid <- expand.grid(
mtry = c(10, 50, 100, 200)  # Number of features considered at each split
)
# Cross-validation control: 3-fold CV for faster performance on large datasets
control <- trainControl(
method = "cv",               # Use cross-validation
number = 3,                  # Number of folds in cross-validation
classProbs = TRUE,           # For classification problems, calculate class probabilities
summaryFunction = twoClassSummary  # Optimize based on AUC (ROC curve)
)
# Train the random forest model with hyperparameter tuning
rf_model <- train(
as.formula(paste(primary_outcome, "~ .")),  # Use the primary outcome dynamically
data = train_data,                         # Training dataset
method = "rf",                             # Random Forest model
tuneGrid = tune_grid,                      # Hyperparameter grid
trControl = control,                       # Cross-validation settings
metric = "ROC"                             # Optimize for AUC (ROC curve)
)
# Extract the best model
best_rf_model <- rf_model$finalModel
prob_predictions <- predict(best_rf_model, x, type = "prob")
prob_predictions <- predict(best_rf_model, model.matrix(~.,x), type = "prob")
prob_predictions <- predict(best_rf_model, model.matrix(~.,train_data), type = "prob")
model.matrix(~.,train_data)
prob_predictions <- predict.train(best_rf_model, model.matrix(~.,train_data), type = "prob")
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
devtools::load_all(".")
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
# Define the response (primary outcome)
y <- train_data[[primary_outcome]]
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(c(primary_outcome,"subjid")))  # Remove the primary outcome column from predictors
# Define a reasonable hyperparameter grid for a dataset with many features
tune_grid <- expand.grid(
mtry = c(10, 50, 100, 200)  # Number of features considered at each split
)
# Cross-validation control: 3-fold CV for faster performance on large datasets
control <- trainControl(
method = "cv",               # Use cross-validation
number = 3,                  # Number of folds in cross-validation
classProbs = TRUE,           # For classification problems, calculate class probabilities
summaryFunction = twoClassSummary  # Optimize based on AUC (ROC curve)
)
#
# Train the random forest model with hyperparameter tuning
rf_model <- train(
as.formula(paste(primary_outcome, "~ .")),  # Use the primary outcome dynamically
data = train_data,                         # Training dataset
method = "rf",                             # Random Forest model
tuneGrid = tune_grid,                      # Hyperparameter grid
trControl = control,                       # Cross-validation settings
metric = "ROC"                             # Optimize for AUC (ROC curve)
)
# # Extract the best model
best_rf_model <- rf_model$finalModel
prob_predictions <- predict.train(best_rf_model, model.matrix(~.,train_data), type = "prob")
prob_predictions <- predict(best_rf_model, model.matrix(~.,train_data), type = "prob")
prob_predictions <- predict(rf_model, x, type = "prob")
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(c(primary_outcome,"subjid")))  # Remove the primary outcome column from predictors
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
# Define the response (primary outcome)
y <- train_data[[primary_outcome]]
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(c(primary_outcome,"subjid")))  # Remove the primary outcome column from predictors
# Define a reasonable hyperparameter grid for a dataset with many features
tune_grid <- expand.grid(
mtry = c(10, 50, 100, 200)  # Number of features considered at each split
)
# Cross-validation control: 3-fold CV for faster performance on large datasets
control <- trainControl(
method = "cv",               # Use cross-validation
number = 3,                  # Number of folds in cross-validation
classProbs = TRUE,           # For classification problems, calculate class probabilities
summaryFunction = twoClassSummary  # Optimize based on AUC (ROC curve)
)
#
# Train the random forest model with hyperparameter tuning
rf_model <- train(
as.formula(paste(primary_outcome, "~ .")),  # Use the primary outcome dynamically
data = train_data,                         # Training dataset
method = "rf",                             # Random Forest model
tuneGrid = tune_grid,                      # Hyperparameter grid
trControl = control,                       # Cross-validation settings
metric = "ROC"                             # Optimize for AUC (ROC curve)
)
prob_predictions <- predict(rf_model, x, type = "prob")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
# Define the response (primary outcome)
y <- train_data[[primary_outcome]]
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(c(primary_outcome)))  # Remove the primary outcome column from predictors
# Define a reasonable hyperparameter grid for a dataset with many features
tune_grid <- expand.grid(
mtry = c(10, 50, 100, 200)  # Number of features considered at each split
)
# Cross-validation control: 3-fold CV for faster performance on large datasets
control <- trainControl(
method = "cv",               # Use cross-validation
number = 3,                  # Number of folds in cross-validation
classProbs = TRUE,           # For classification problems, calculate class probabilities
summaryFunction = twoClassSummary  # Optimize based on AUC (ROC curve)
)
#
# Train the random forest model with hyperparameter tuning
rf_model <- train(
as.formula(paste(primary_outcome, "~ .")),  # Use the primary outcome dynamically
data = train_data,                         # Training dataset
method = "rf",                             # Random Forest model
tuneGrid = tune_grid,                      # Hyperparameter grid
trControl = control,                       # Cross-validation settings
metric = "ROC"                             # Optimize for AUC (ROC curve)
)
prob_predictions <- predict(rf_model, x, type = "prob")
prob_predictions
nrow(train_data)
primary_outcome <- "nafld"
weights <- get_weights(train_data, primary_outcome)
weights <- get_weights(train_data, primary_outcome)
devtools::load_all(".")
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
primary_outcome <- "nafld"
#
weights <- get_weights(train_data, primary_outcome)
# Define the response (primary outcome)
y <- train_data[[primary_outcome]]
# Define the predictors (covariates and secondary outcome)
x <- train_data %>% select(-one_of(primary_outcome))  # Remove the primary outcome column from predictors
# Define a reasonable hyperparameter grid for a dataset with many features
tune_grid <- expand.grid(
mtry = c(10, 50, 100, 200)  # Number of features considered at each split
)
# Cross-validation control: 3-fold CV for faster performance on large datasets
control <- trainControl(
method = "cv",               # Use cross-validation
number = 3,                  # Number of folds in cross-validation
classProbs = TRUE,           # For classification problems, calculate class probabilities
summaryFunction = twoClassSummary  # Optimize based on AUC (ROC curve)
)
# Train the random forest model with hyperparameter tuning
rf_model <- train(
as.formula(paste(primary_outcome, "~ .")),  # Use the primary outcome dynamically
data = train_data,                         # Training dataset
method = "rf",                             # Random Forest model
tuneGrid = tune_grid,                      # Hyperparameter grid
trControl = control,                       # Cross-validation settings
metric = "ROC"                             # Optimize for AUC (ROC curve)
)
# Get predicted probabilities for both case and control classes
prob_predictions <- predict(rf_model, x, type = "prob")
prob_predictions
combined_weights <- ifelse(train_data[[primary_outcome]] == "case",
prob_predictions[, "case"],     # Assign prob_case to case-labeled participants
prob_predictions[, "control"])  # Assign prob_control to control-labeled participants
train_data[[primary_outcome]]
combined_weights <- ifelse(train_data[[primary_outcome]] == "Case",
prob_predictions[, "Case"],     # Assign prob_case to case-labeled participants
prob_predictions[, "Control"])  # Assign prob_control to control-labeled participants
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
devtools::load_all(".")
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
weights <- get_weights(train_data, primary_outcome)
weights
devtools::load_all(".")
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
weights <- get_weights(train_data, primary_outcome)
weights
devtools::load_all(".")
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
primary_outcome <- "nafld"
ip_weights <- get_weights(train_data, primary_outcome)
alpha <- 0.5
cv_iter <- 5
secondary_outcome <- "obesity"
multivariate_results <- perform_multivariate_analysis(train_data,secondary_outcome, alpha, cv_iter,weights=ip_weights$weights)
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
head(train_data)
as_tibble(train_data)
column_to_rownames(train_data, loc = 1)
# Set the 'RowNames' column as row names
rownames(train_data) <- train_data$subjid
# Remove the 'RowNames' column
train_data <- train_data[, -which(names(train_data) == "subjid")]
train_data
file_path_participant <- "../../related_material/dataset/obesity/ST002269_data_metadata.csv"
file_path_metabolite <- "../../related_material/dataset/obesity/ST002269_data_mets.csv"
file_ext <- "csv"
participant_data <- read_file(file_path = file_path_participant,
file_ext = file_ext)
metabolite_data <- read_file(file_path = file_path_metabolite,
file_ext = file_ext)
processed_data <- pre_process(participant_data = participant_data,
metabolite_data = metabolite_data,
metabolite_ids_are_rows = FALSE,
case_control_col="nafld")
participant_data_out <- processed_data$participant_data
metabolite_data_out <- processed_data$metabolite_data
combined_data <- processed_data$combined_data
train_data <- processed_data$train
test_data <- processed_data$test
# Set the 'RowNames' column as row names
rownames(train_data) <- train_data$subjid
# Remove the 'RowNames' column
train_data <- train_data[, -which(names(train_data) == "subjid")]
primary_outcome <- "nafld"
ip_weights <- get_weights(train_data, primary_outcome)
alpha <- 0.5
cv_iter <- 5
secondary_outcome <- "obesity"
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = metabolite_data)  # Create model matrix (no intercept)
# Set the 'RowNames' column as row names
rownames(metabolite_data) <- metabolite_data$subjid
# Remove the 'RowNames' column
metabolite_data <- metabolite_data[, -which(names(metabolite_data) == "subjid")]
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = metabolite_data)  # Create model matrix (no intercept)
metabolite_data
train_data
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
secondary_outcome <- "obesity"
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
x <- model.matrix(secondary_outcome ~ . - 1, data = train_data)  # Create model matrix (no intercept)
sapply(train_data, length)
sum(sapply(train_data, length) != 97)
train_data
head(colnames(train_data))
secondary_outcome <- "obese"
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
train_data
x <- model.matrix(as.factor("obese") ~ . - 1, data = train_data)  # Create model matrix (no intercept)
x <- model.matrix(as.factor(age) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
x <- model.matrix(as.factor(one_of(secondary_outcome)) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
x <- model.matrix(as.factor(obese) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
# Define the secondary outcome variable
secondary_outcome <- "obese"  # Example value, change based on your data
# Create the model matrix using a dynamic formula
x <- model.matrix(as.formula(paste(secondary_outcome, "~ . - 1")), data = train_data)
# View the result
print(x)
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
y <- as.factor(train_data$secondary_outcome)  # Outcome variable (factor)
x <- model.matrix(as.factor(secondary_outcome) ~ . - 1, data = train_data)  # Create model matrix (no intercept)
x <- model.matrix(as.formula(paste(secondary_outcome, "~ . - 1")), data = train_data)  # Create model matrix (no intercept)
y <- as.factor(train_data$secondary_outcome)  # Outcome variable (factor)
cv_fit <- cv.glmnet(x, y, family = "binomial", alpha = alpha, weights = weights, nfolds = cv_iter)
weights()
ip_weights <- get_weights(train_data, primary_outcome)
# Step 2: Get Weights (if applicable, based on outcomes)
ip_weights <- get_weights(train_data, primary_outcome)
cv_fit <- cv.glmnet(x, y, family = "binomial", alpha = alpha, weights = ip_weights$values, nfolds = cv_iter)
y <- as.factor(train_data$secondary_outcome)  # Outcome variable (factor)
y <- as.factor(train_data[[secondary_outcome]])  # Outcome variable (factor)
cv_fit <- cv.glmnet(x, y, family = "binomial", alpha = alpha, weights = ip_weights$values, nfolds = cv_iter)
# Step 1: Extract the coefficients at the best lambda
coef_matrix <- coef(cv_fit, s = "lambda.min")
coef_df <- as.data.frame(as.matrix(coef_matrix))
coef_df$feature <- rownames(coef_df)
colnames(coef_df)[1] <- "coefficient"
coef_df <- coef_df %>% filter(feature != "(Intercept)")  # Remove intercept
# Step 2: Get the top 10 coefficients by absolute value (excluding intercept)
top_ten_coef <- coef_df %>%
arrange(desc(abs(coefficient))) %>%
head(10)
# Step 3: Calculate AUC-ROC on the training data
y_pred <- predict(cv_fit, newx = x, s = "lambda.min", type = "response")
roc_obj <- roc(y, y_pred)  # Calculate ROC curve
# Step 4: Calculate the AUC value and 95% confidence interval for AUC
auc_value <- auc(roc_obj)  # AUC value
auc_ci <- ci.auc(roc_obj)  # 95% Confidence interval
# Step 5: Plot ROC curve with ggplot2 and add 95% CI
roc_plot <- ggroc(roc_obj) +
geom_line(size = 1) +
ggtitle(paste("ROC Curve (AUC = ", round(auc_value, 3), ")", sep = "")) +
theme_minimal() +
annotate("text", x = 0.8, y = 0.2,
label = paste0("AUC 95% CI: (",
round(auc_ci[1], 3), ", ",
round(auc_ci[3], 3), ")"),
size = 5, hjust = 0)
# Return the top ten coefficients, AUC value, and the ROC curve plot
return(list(
top_ten_coefficients = top_ten_coef,
auc_value = auc_value,
auc_ci = auc_ci,
roc_plot = roc_plot
))
results <- list(
top_ten_coefficients = top_ten_coef,
auc_value = auc_value,
auc_ci = auc_ci,
roc_plot = roc_plot
)
results$top_ten_coefficients
results$roc_plot
prin(results$roc_plot)
print(results$roc_plot)
